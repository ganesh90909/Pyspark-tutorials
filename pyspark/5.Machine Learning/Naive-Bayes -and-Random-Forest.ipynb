{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master='local')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Naive bayes example').\\\n",
    "config('spark.some.config.option','some-value').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris=spark.read.csv('Iris-data.csv',inferSchema=True,header=True)\n",
    "iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=iris.withColumnRenamed('SepalLengthCm','sepalLength')\n",
    "iris=iris.withColumnRenamed('SepalWidthCm','sepalWidth')\n",
    "iris=iris.withColumnRenamed('PetalLengthCm','petalLength')\n",
    "iris=iris.withColumnRenamed('PetalWidthCm','petalWidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-----------+----------+-----------+\n",
      "| Id|sepalLength|sepalWidth|petalLength|petalWidth|    Species|\n",
      "+---+-----------+----------+-----------+----------+-----------+\n",
      "|  1|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|  2|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|  3|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|  4|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|  5|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "+---+-----------+----------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Id', 'int'),\n",
       " ('sepalLength', 'double'),\n",
       " ('sepalWidth', 'double'),\n",
       " ('petalLength', 'double'),\n",
       " ('petalWidth', 'double'),\n",
       " ('Species', 'string')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=iris.drop('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|       sepalLength|         sepalWidth|       petalLength|        petalWidth|       Species|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|               150|                150|               150|               150|           150|\n",
      "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|          null|\n",
      "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|          null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge features to create a feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|         features|    species|\n",
      "+-----------------+-----------+\n",
      "|[5.1,3.5,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.0,1.4,0.2]|Iris-setosa|\n",
      "|[4.7,3.2,1.3,0.2]|Iris-setosa|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|\n",
      "|[5.0,3.6,1.4,0.2]|Iris-setosa|\n",
      "+-----------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris2=iris.rdd.map(lambda x:Row(features=Vectors.dense(x[:-1]),species=x[-1])).toDF()\n",
    "iris2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index label column with string indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "strindexer=StringIndexer(inputCol='species',outputCol='label')\n",
    "stages=[strindexer]\n",
    "pipeline=Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----+\n",
      "|         features|    species|label|\n",
      "+-----------------+-----------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|Iris-setosa|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|Iris-setosa|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|Iris-setosa|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|Iris-setosa|  0.0|\n",
      "+-----------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df=pipeline.fit(iris2).transform(iris2)\n",
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+-----+\n",
      "|        species|label|count|\n",
      "+---------------+-----+-----+\n",
      "|    Iris-setosa|  0.0|   50|\n",
      "| Iris-virginica|  2.0|   50|\n",
      "|Iris-versicolor|  1.0|   50|\n",
      "+---------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df.groupBy('species','label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=iris_df.randomSplit([0.8,0.2],seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build cross-validation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb=NaiveBayes(featuresCol='features',labelCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid=ParamGridBuilder().addGrid(nb.smoothing,[0,1,2,4,8]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator=MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv=CrossValidator(estimator=nb,estimatorParamMaps=param_grid,evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model=cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|         features|    species|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|[4.4,3.2,1.3,0.2]|Iris-setosa|  0.0|[-10.991182067744...|[0.69043491224626...|       0.0|\n",
      "|[4.5,2.3,1.3,0.3]|Iris-setosa|  0.0|[-10.437996923451...|[0.53954099724437...|       0.0|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|  0.0|[-11.409627485465...|[0.65314888582843...|       0.0|\n",
      "|[4.6,3.2,1.4,0.2]|Iris-setosa|  0.0|[-11.326047137369...|[0.68288612816400...|       0.0|\n",
      "|[4.6,3.4,1.4,0.3]|Iris-setosa|  0.0|[-11.903399773384...|[0.68013704003242...|       0.0|\n",
      "+-----------------+-----------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred=cv_model.transform(train_df)\n",
    "train_pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|         features|    species|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|[4.3,3.0,1.1,0.1]|Iris-setosa|  0.0|[-9.9571767911548...|[0.72010736400660...|       0.0|\n",
      "|[4.4,2.9,1.4,0.2]|Iris-setosa|  0.0|[-10.856296304349...|[0.63406956123413...|       0.0|\n",
      "|[4.4,3.0,1.3,0.2]|Iris-setosa|  0.0|[-10.772715956253...|[0.66463053886253...|       0.0|\n",
      "|[4.8,3.1,1.6,0.2]|Iris-setosa|  0.0|[-11.744492555091...|[0.64516268270226...|       0.0|\n",
      "|[5.0,3.3,1.4,0.2]|Iris-setosa|  0.0|[-11.719383524683...|[0.71215569656321...|       0.0|\n",
      "+-----------------+-----------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred=cv_model.transform(test_df)\n",
    "test_pred.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four metrics are available:\n",
    "    <ul>\n",
    "    <li>f1</li>\n",
    "    <li>weightedRecall</li>\n",
    "    <li>weightedPrecision</li>\n",
    "    <li>accuracy</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training(f1):  0.9523551844980417\n",
      "accuracy of training(weightedRecall):  0.9523809523809523\n",
      "accuracy of training(weightedPrecision):  0.9530175936680002\n",
      "accuracy of training(accuracy):  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of training(f1): ',evaluator.setMetricName('f1').evaluate(train_pred))\n",
    "print('accuracy of training(weightedRecall): ',evaluator.setMetricName('weightedRecall').evaluate(train_pred))\n",
    "print('accuracy of training(weightedPrecision): ',evaluator.setMetricName('weightedPrecision').evaluate(train_pred))\n",
    "print('accuracy of training(accuracy): ',evaluator.setMetricName('accuracy').evaluate(train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of test data:  0.958119658119658\n",
      "accuracy of test data:  0.9583333333333335\n",
      "accuracy of test data:  0.9635416666666667\n",
      "accuracy of test data:  0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of test data: ',evaluator.setMetricName('f1').evaluate(test_pred))\n",
    "print('accuracy of test data: ',evaluator.setMetricName('weightedRecall').evaluate(test_pred))\n",
    "print('accuracy of test data: ',evaluator.setMetricName('weightedPrecision').evaluate(test_pred))\n",
    "print('accuracy of test data: ',evaluator.setMetricName('accuracy').evaluate(test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel._java_obj.getSmoothing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 40,\n",
       "             Row(label=1.0, prediction=1.0): 39,\n",
       "             Row(label=2.0, prediction=2.0): 41,\n",
       "             Row(label=1.0, prediction=2.0): 4,\n",
       "             Row(label=2.0, prediction=1.0): 2})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_conf_mat=train_pred.select('label','prediction')\n",
    "train_conf_mat.rdd.zipWithIndex().countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 10,\n",
       "             Row(label=1.0, prediction=1.0): 7,\n",
       "             Row(label=2.0, prediction=2.0): 6,\n",
       "             Row(label=2.0, prediction=1.0): 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conf_mat=test_pred.select('label','prediction')\n",
    "test_conf_mat.rdd.zipWithIndex().countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rt=RandomForestClassifier(featuresCol='features',labelCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid=ParamGridBuilder().addGrid(rt.maxDepth,[2,3,4,5]).addGrid(rt.minInfoGain,[0.0,0.1,0.2,0.3]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator=MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv=CrossValidator(estimator=rt,estimatorParamMaps=param_grid,evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model=cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----+--------------+-------------+----------+\n",
      "|         features|    species|label| rawPrediction|  probability|prediction|\n",
      "+-----------------+-----------+-----+--------------+-------------+----------+\n",
      "|[4.4,3.2,1.3,0.2]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.5,2.3,1.3,0.3]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.6,3.2,1.4,0.2]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.6,3.4,1.4,0.3]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "+-----------------+-----------+-----+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt_train_pred=cv_model.transform(train_df)\n",
    "rt_train_pred.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----+--------------+-------------+----------+\n",
      "|         features|    species|label| rawPrediction|  probability|prediction|\n",
      "+-----------------+-----------+-----+--------------+-------------+----------+\n",
      "|[4.3,3.0,1.1,0.1]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.4,2.9,1.4,0.2]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.4,3.0,1.3,0.2]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.8,3.1,1.6,0.2]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[5.0,3.3,1.4,0.2]|Iris-setosa|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "+-----------------+-----------+-----+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt_test_pred=cv_model.transform(test_df)\n",
    "rt_test_pred.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training(f1):  0.9523809523809523\n",
      "accuracy of training(weightedRecall):  0.9523809523809523\n",
      "accuracy of training(weightedPrecision):  0.9523809523809523\n",
      "accuracy of training(accuracy):  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of training(f1): ',evaluator.setMetricName('f1').evaluate(rt_train_pred))\n",
    "print('accuracy of training(weightedRecall): ',evaluator.setMetricName('weightedRecall').evaluate(rt_train_pred))\n",
    "print('accuracy of training(weightedPrecision): ',evaluator.setMetricName('weightedPrecision').evaluate(rt_train_pred))\n",
    "print('accuracy of training(accuracy): ',evaluator.setMetricName('accuracy').evaluate(rt_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of testing(f1):  0.958119658119658\n",
      "accuracy of testing(weightedRecall):  0.9583333333333335\n",
      "accuracy of testing(weightedPrecision):  0.9635416666666667\n",
      "accuracy of testing(accuracy):  0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of testing(f1): ',evaluator.setMetricName('f1').evaluate(rt_test_pred))\n",
    "print('accuracy of testing(weightedRecall): ',evaluator.setMetricName('weightedRecall').evaluate(rt_test_pred))\n",
    "print('accuracy of testing(weightedPrecision): ',evaluator.setMetricName('weightedPrecision').evaluate(rt_test_pred))\n",
    "print('accuracy of testing(accuracy): ',evaluator.setMetricName('accuracy').evaluate(rt_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 40,\n",
       "             Row(label=1.0, prediction=1.0): 40,\n",
       "             Row(label=2.0, prediction=1.0): 3,\n",
       "             Row(label=2.0, prediction=2.0): 40,\n",
       "             Row(label=1.0, prediction=2.0): 3})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_train_confmatrix=rt_train_pred.select('label','prediction')\n",
    "rt_train_confmatrix.rdd.zipWithIndex().countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 10,\n",
       "             Row(label=1.0, prediction=1.0): 7,\n",
       "             Row(label=2.0, prediction=2.0): 6,\n",
       "             Row(label=2.0, prediction=1.0): 1})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_test_confmatrix=rt_test_pred.select('label','prediction')\n",
    "rt_test_confmatrix.rdd.zipWithIndex().countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel._java_obj.getMaxDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel._java_obj.getMinInfoGain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

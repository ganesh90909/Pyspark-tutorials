{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc=SparkContext()\n",
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| x1|    x2| x3|\n",
      "+---+------+---+\n",
      "|  a| apple|  2|\n",
      "|  b|banana|  3|\n",
      "|  c|orange|  1|\n",
      "|  a| peach|  5|\n",
      "|  b|  pine| 11|\n",
      "|  b| grape| 10|\n",
      "+---+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf=pd.DataFrame({\n",
    "    'x1':['a','b','c','a','b','b'],\n",
    "    'x2':['apple','banana','orange','peach','pine','grape'],\n",
    "    'x3':[2,3,1,5,11,10]\n",
    "})\n",
    "\n",
    "df=spark.createDataFrame(pdf)\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***StringIndexer*** maps a string column to a index column which is categorical.**The indices start with 0 and are labeled by frequencies.** If the column is numeric,then it is first converted to string and *StringIndexer* is applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StringIndexer need 3 steps to implement:\n",
    "      <br> **Build the StringIndexer model** :specify input column and output column.\n",
    "      <br> **Learn the StringIndexer model** :*fit* the model with the data.\n",
    "      <br> **Executing the indexing** :*transform* function is called for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+--------+\n",
      "| x1|    x2| x3|Index_x1|\n",
      "+---+------+---+--------+\n",
      "|  a| apple|  2|     1.0|\n",
      "|  b|banana|  3|     0.0|\n",
      "|  c|orange|  1|     2.0|\n",
      "|  a| peach|  5|     1.0|\n",
      "|  b|  pine| 11|     0.0|\n",
      "|  b| grape| 10|     0.0|\n",
      "+---+------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#build Indexer\n",
    "stringindexer=StringIndexer(inputCol='x1',outputCol='Index_x1')\n",
    "\n",
    "#learn Indexer\n",
    "stringindexer_model=stringindexer.fit(df)\n",
    "\n",
    "#execute the transform\n",
    "df_stringindexer=stringindexer_model.transform(df)\n",
    "\n",
    "df_stringindexer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OneHotEncoder*** converts each category of *StringIndexed* column to a sparse vector.Each sparse vector has atmost **one single active element** that indicate the category index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| x1|\n",
      "+---+\n",
      "|  a|\n",
      "|  b|\n",
      "|  c|\n",
      "|  a|\n",
      "|  b|\n",
      "|  b|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_x1=df.select('x1')\n",
    "df_x1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StringIndex x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| x1|index_x1|\n",
      "+---+--------+\n",
      "|  a|     1.0|\n",
      "|  b|     0.0|\n",
      "|  c|     2.0|\n",
      "|  a|     1.0|\n",
      "|  b|     0.0|\n",
      "|  b|     0.0|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Stringindexed=StringIndexer(inputCol='x1',outputCol='index_x1').fit(df_x1).transform(df_x1)\n",
    "df_Stringindexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding format: 'string index': ['string indices vector size', 'index of string index in string indices vector', **1.0** ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the string indices vector is [0.0, 1.0, 2.0]. Therefore, the mapping between string indices and sparse vectors are:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>0.0: [3, [0], [1.0]]</li>\n",
    "    <li>1.0: [3, [1], [1.0]]</li>\n",
    "    <li>2.0: [3, [2], [1.0]]</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+\n",
      "| x1|index_x1|    sparse_x1|\n",
      "+---+--------+-------------+\n",
      "|  a|     1.0|(3,[1],[1.0])|\n",
      "|  b|     0.0|(3,[0],[1.0])|\n",
      "|  c|     2.0|(3,[2],[1.0])|\n",
      "|  a|     1.0|(3,[1],[1.0])|\n",
      "|  b|     0.0|(3,[0],[1.0])|\n",
      "|  b|     0.0|(3,[0],[1.0])|\n",
      "+---+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder=OneHotEncoder(dropLast=False,inputCol='index_x1',outputCol='sparse_x1').transform(df_Stringindexed)\n",
    "onehot_encoder.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHotEncoder** by default will drop the last category. So the string indices vector becomes [0.0, 1.0], and the mappings between string indices and sparse vectors are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>0.0: [2, [0], [1.0]]</li>\n",
    "    <li>1.0: [2, [1], [1.0]]</li>\n",
    "    <li>2.0: [2, [ ], [ ]]</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+\n",
      "| x1|index_x1|    sparse_x1|\n",
      "+---+--------+-------------+\n",
      "|  a|     1.0|(2,[1],[1.0])|\n",
      "|  b|     0.0|(2,[0],[1.0])|\n",
      "|  c|     2.0|    (2,[],[])|\n",
      "|  a|     1.0|(2,[1],[1.0])|\n",
      "|  b|     0.0|(2,[0],[1.0])|\n",
      "|  b|     0.0|(2,[0],[1.0])|\n",
      "+---+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder=OneHotEncoder(inputCol='index_x1',outputCol='sparse_x1').transform(df_Stringindexed)\n",
    "onehot_encoder.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can convert the ***sparse vectors*** to ***Dense vectors*** which is a numpy matrix used in statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 0., 0.]), array([0., 1., 0.]), array([0., 0., 1.])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import DenseVector, SparseVector, DenseMatrix, SparseMatrix\n",
    "x = [SparseVector(3, {0: 1.0}).toArray()] + \\\n",
    "    [SparseVector(3, {1: 1.0}).toArray()] + \\\n",
    "    [SparseVector(3, {2: 1.0}).toArray()]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "sc=pyspark.SparkContext()\n",
    "spark=pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Variable to Categorical Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions which can convert continuous variable into a categorical variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *pyspark.ml.feature.Binarizer*: splits a column given a threshold value.\n",
    "* *pyspark.ml.feature.Bucketizer*: splits a column into categories given several breakpoints(with n+1 split points,n categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                  x1|                x2|\n",
      "+--------------------+------------------+\n",
      "| -1.0856306033005612| 4.385722446796244|\n",
      "|  0.9973454465835858|0.5967789660956835|\n",
      "| 0.28297849805199204|3.9804425533043144|\n",
      "|  -1.506294713918092| 7.379954057320357|\n",
      "| -0.5786002519685364|1.8249173045349998|\n",
      "|   1.651436537097151|1.7545175614749253|\n",
      "|  -2.426679243393074|5.3155137384183835|\n",
      "|-0.42891262885617726| 5.318275870968661|\n",
      "|   1.265936258705534| 6.344009585513211|\n",
      "| -0.8667404022651017| 8.494317940777895|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "data=pd.DataFrame({'x1':np.random.randn(10),'x2':np.random.rand(10)*10})\n",
    "np.random.seed(seed=None)\n",
    "df=spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------+------+\n",
      "|                  x1|                x2|x1_new|x2_new|\n",
      "+--------------------+------------------+------+------+\n",
      "| -1.0856306033005612| 4.385722446796244|   0.0|   1.0|\n",
      "|  0.9973454465835858|0.5967789660956835|   1.0|   0.0|\n",
      "| 0.28297849805199204|3.9804425533043144|   1.0|   1.0|\n",
      "|  -1.506294713918092| 7.379954057320357|   0.0|   2.0|\n",
      "| -0.5786002519685364|1.8249173045349998|   0.0|   0.0|\n",
      "|   1.651436537097151|1.7545175614749253|   1.0|   0.0|\n",
      "|  -2.426679243393074|5.3155137384183835|   0.0|   2.0|\n",
      "|-0.42891262885617726| 5.318275870968661|   0.0|   2.0|\n",
      "|   1.265936258705534| 6.344009585513211|   1.0|   2.0|\n",
      "| -0.8667404022651017| 8.494317940777895|   0.0|   3.0|\n",
      "+--------------------+------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Binarizer,Bucketizer\n",
    "#threshold=0 for binarizer\n",
    "binarizer=Binarizer(threshold=0,inputCol='x1',outputCol='x1_new')\n",
    "\n",
    "#providing 5 split points to generate 4 buckets\n",
    "bucketizer=Bucketizer(splits=[0,2.5,5,7.5,10],inputCol='x2',outputCol='x2_new')\n",
    "\n",
    "#pipeline stages\n",
    "from pyspark.ml import Pipeline\n",
    "stage=[binarizer,bucketizer]\n",
    "pipe=Pipeline(stages=stage)\n",
    "\n",
    "#fit the model and transform the data\n",
    "pipe.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
